#+TITLE:    Preferences over lotteries and the independence axiom
#+AUTHOR:    Christoph
#+EMAIL:    
#+DATE:      2014-09-26 Fri
#+DESCRIPTION:
#+KEYWORDS:
#+LANGUAGE:  en
#+OPTIONS:   H:3 num:t toc:nil \n:nil @:t ::t |:t ^:t -:t f:t *:t <:t
#+OPTIONS:   TeX:t LaTeX:t skip:nil d:nil todo:t pri:nil tags:not-in-toc
#+INFOJS_OPT: view:nil toc:nil ltoc:nil mouse:underline buttons:0 path:http://orgmode.org/org-info.js
#+EXPORT_SELECT_TAGS: export
#+EXPORT_EXCLUDE_TAGS: noexport

* Using the independence axiom to deduce preferences
This program can be used to deduce preferences over lotteries from preferences over other lotteries. This is done using the independence axiom directly. It can also generate simple exercises where you can try to solve this problem yourself by hand.

The question we ask first is the following: If we have a certain set of preference relations, say an individual prefers lottery $L1$ over $L1'$, can we deduce that he prefers lottery another $L$ over $L'$? We use the example we had in the lecture where we have three states and $$L1 = [0.1,0.8,0.1]\succ[0.0,1.0,0.0]=L1'.$$ Now we want to know whether we can conclude that $L=[0.55,0.4,0.05]$ is preferred to $L'=[0.5,0.5,0.0]$. The answer is yes because (i) by the independence axiom $$0.5*L1+0.5*[1,0,0]\succ 0.5*L1'+0.5*[1,0,0]$$ and (ii) this is equivalent to $L\succ L'$ as $0.5*L1+0.5*[1,0,0]=L$ and $0.5*L1'+0.5*[1,0,0]=L'$.

How can we solve such an exercise in general? To solve the example we had to find the lottery $[1,0,0]$ and the weight $0.5$. If we know that $L1\succ L1'$ and we want to conclude that $L\succ L'$, we have to find a lottery $[x_1,x_2,x_3]$ and a weight $x_0$ such that
- $$x_0 L1 + (1-x_0) [x_1,x_2,x_3] = L$$
- $$x_0 L1' +(1-x_0)[x_1,x_2,x_3]=L'.$$
If we can find such $x_0$ and $[x_1,x_2,x_3]$, then we can conclude by the independence axiom that $L\succ L'$. Note that the two equations above consist actually of three equations each. Take the first one and let us denote $L1$ as $[a,b,c]$ and $L$ by $[d,e,f]$. Then the first equation could also be written as

$$x_0\left(\begin{matrix}a\\b\\c\end{matrix}\right) +(1-x_0)\left(\begin{matrix}x_1\\x_2\\x_3\end{matrix}\right)=\left(\begin{matrix}d\\e\\f\end{matrix}\right)$$
which are of course three equations

    $$x_0a+(1-x_0)x_1=d$$
    $$x_0b+(1-x_0)x_2=e$$
    $$x_0c+(1-x_0)x_3=f.$$

The second condition is, of course, similar. Hence, we have six equations but only four unknowns: $[x_0,x_1,x_2,x_3]$. This alone means that there is a good chance that there is no solution. What makes the situation even trickier is that our solution has to satisfy a few conditions. Since $[x_1,x_2,x_3]$ is a lottery, all three variables have to be between 0 and 1 (they are probabilities!) and they have to sum to 1. Furthermore, $x_0$ is also a probabiltiy and has, therefore, to be between 0 and 1. So we get the additional constraints
$$0\leq x_0,x_1,x_2,x_3\leq 1\qquad x_1+x_2+x_3=1.$$
If this system of equations and inequality constraints has no solution, then we do not know whether the agent prefers lottery $L$ over $L'$. 

** Using the PC to solve such exercises

The program below uses the "system of non-linear equation" solver from the openopt package to (try to) solve exactly the problem we just described. We try to find a solution $x=[x[0],x[1],x[2],x[3]]$ of the six equations described above. The solution has to satisfy the constraint $x[1]+x[2]+x[3]=1$ which written in below in matrix notation $Ax=beq$ where $A=[0,1,1,1]$ and $beq=1$. To make sure that we have probabilities, we have a lower bound of $lb=[0,0,0,0]$ and an upper bound of $ub=[1,1,1,1]$. These bounds are generated with a loop. This has the advantage that you can use the program also if you have lotteries with more than three states. After this we create a function $g$ which plugs a given $x$ into the six equations (it subtracts the right hand side from the left hand side of each of these six equations and returns the differences). If for some feasible $x$ $g$ returns zero, then we are done: We have found a solution! If there is no such solution, then we are also done: We do not know whether $L$ is $L'$ are preferred. Hence, we ask the non-linear equation solver to try to find a solution $x$ such that $g$ is zero.


#+RESULTS:

#+begin_src python :session 1dim :results output :exports both :tangle lottery_1dim.py
  from numpy import *#imports the numpy module for numerical mathematic in python
  from openopt import SNLE #importing a solver for systems of non-linear equations

  L1 = [0.1,0.8,0.1]#this is the starting lottery: we know that L1 is preferred to L1p
  L1p = [0.0,1.0,0.0]

  L = [0.55,0.4,0.05]#we want to know if L is preferred to Lp?
  Lp = [0.5,0.5,0.0]


  x0 = [0.5]#this array contains the starting value for the algorithm below
  lb = [0.0]#lower bound: probabilities have to be weakly higher than 0
  ub = [1.0]#upper bound: probabilities have to be weakly lower than 1
  A = [0.0]#this will be used to express the constraint that the probabilities in a lottery have to sum to 1
  beq = [1.0]#this is the 1 to which the the probabilities in a lottery have to sum

  #the following loop makes sure that the constraints have the right dimension, i.e. for each probability we have an upper and lower bound etc.
  j = 0
  while j<len(L1):
      x0.append(1.0/len(L1))
      lb.append(0.0)
      ub.append(1.0)
      A.append(1.0)
      j+=1

  #this vector function is the key equation: if all its components are zero, then L is preferred to Lp. the function returns a list where each entry of this list tells us by how much one of the necessary equations is violated
  def g(x):
      j = 0
      out = []
      while j<len(L1):
          out.append(L1[j]*x[0]+(1-x[0])*x[1+j]-L[j])
          out.append(L1p[j]*x[0]+(1-x[0])*x[1+j]-Lp[j])
          j+=1
      return out

  #setting up the solver to solve the vector equation g=0
  p = SNLE(g,x0,lb=lb,ub=ub,Aeq = [A],beq=beq)
  r = p.solve('nssolve')



  #this presents the output
  if r.stopcase==1:
      formatted_lottery = ()
      for m in r.xf:
          formatted_lottery = formatted_lottery + (round(m,2),)
      print 'The agent prefers L over Lp because L=',round(r.xf[0],2),'* L1p + (1 -', round(r.xf[0],2),') *',formatted_lottery[1:],' and Lp=',round(r.xf[0],2),'* L1p + (1 -', round(r.xf[0],2),') *',formatted_lottery[1:],'.'
  elif r.stopcase==0:
      print 'The solver cannot solve the problem. The implication might or might not be valid.'
  else:
      print 'No implication can be made.'

#+end_src

#+RESULTS:
#+begin_example

>>> >>> >>> >>> >>> >>> >>> >>> >>> >>> >>> >>> >>> >>> >>> >>> >>> >>> ... >>> ... ... ... ... ... ... >>> ... ... ... ... ... ... ... ... ... >>> ... >>> 
------------------------- OpenOpt 0.5621 -------------------------
problem: unnamed   type: SNLE
solver: nssolve
  iter  objFunVal  log10(maxResidual)  
    0  3.333e-01            -100.00 
   10  9.600e-02              -2.87 
   20  5.000e-03              -2.77 
   30  5.197e-04             -15.26 
   40  4.343e-05             -15.35 
   50  9.790e-07             -15.48 
   52  4.525e-07             -15.35 
istop: 15 (solution with required ftol and contol has been reached)
Solver:   Time Elapsed = 0.14 	CPU Time Elapsed = 0.14
objFunValue: 4.5249483e-07 (feasible, MaxResidual = 4.44089e-16)
... ... ... ... ... ... ... ... ... ... The agent prefers L over Lp because L= 0.5 * L1p + (1 - 0.5 ) * (1.0, 0.0, 0.0)  and Lp= 0.5 * L1p + (1 - 0.5 ) * (1.0, 0.0, 0.0) .
#+end_example

** What if we know more?

If we have more information, that is if we know several preference relations, we are more likely to be able to make a prediction. If we know that $L1_1\succ L1_1'$ and $L1_2\succ L1_2'$ and if we can find weights $x_0$, $x_1$ as well as a lottery $[x_2,x_3,x_4]$ (I stick to three states for now) such that 
$$x_0 L1_1+x_1 L1_2+(1-x_0-x_1)[x_2,x_3,x_4]=L$$ 
and at the same time 
$$x_0 L1_1'+x_1 L1_2'+(1-x_0-x_1)[x_2,x_3,x_4]=L'$$
then we can conlude by the independence axiom that $L\succ L'$. Note that we still have six equations but we have one additional variable to satisfy these six equations! If we knew even more preference relations we would get more and more variables while the number of equations stays the same. This is the mathematical equivalent to saying that we are more likely to be able to draw a conclusion if we have more information.

The program below extends the previous one by allowing whole lists of known preference relations. It then determines whether we can say that the agent prefers lottery $L$ to $L'$.

#+begin_src python :session general :results output :exports both :tangle lottery_mult.py
  from numpy import *
  from openopt import SNLE #importing a solver for systems of non-linear equations

  L1 = [[0.1,0.8,0.1],[0.7,0.2,0.1]]#list of lotteries where preference relation is known: the k-th lottery in this vector is preferred to the k-th lottery in the vector L1p
  L1p = [[0.0,1.0,0.0],[0.5,0.5,0.0]]

  L = [0.375,0.3,0.325]#we want to know whether L is preferred to Lp
  Lp = [0.25,0.5,0.25]

  n = len(L1)#number of known observed preference relations

  x0 = []#this list will contain the starting value for the problem below

  j = 0
  A = [] #will be used to express the constraint that the sum of the weights on the known lotteries must be less than 1
  Aeq = []#will be used to express the constraint that the probabilities in the new to be determined lottery sum to 1
  lb = []#lower bound: probabilities have to be weakly higher than 0
  ub = []#upper bound: probabilities have to be weakly lower than 1
  #the following 2 loops makes sure that the constraints have the right dimension, i.e. for each probability we have an upper and lower bound etc.
  while j<n:
      x0.append(1.0/n)
      lb.append(0.0)
      ub.append(1.0)
      A.append(1.0)
      Aeq.append(0.0)
      j+=1

  j = 0
  while j<len(L1[0]):
      x0.append(1.0/len(L1))
      lb.append(0.0)
      ub.append(1.0)
      A.append(0.0)
      Aeq.append(1.0)
      j+=1

  #this will be used to express the constraint that the probabilities in the to be determined new lottery have to sum to 1
  beq = 1.0
  b = 1.0#this is the 1 which is the highest possible number for the sum of weights on the original lotteries in L1 (and L1p respectively)

  #this vector function is the key equation: if all its components are zero, then L is preferred to Lp
  def g(x):
      j = 0
      out = []
      while j<len(L1[0]):
          k = 0
          rest_prob = 1.0
          temp1 = 0.0
          temp2 = 0.0
          while k<n:
              temp1 = temp1 + L1[k][j]*x[k]
              temp2 = temp2 + L1p[k][j]*x[k]
              rest_prob = rest_prob - x[k]
              k+=1
          out.append(temp1+rest_prob*x[n+j]-L[j])
          out.append(temp2+rest_prob*x[n+j]-Lp[j])
          j+=1
      return out

  #setting up the solver to solve the vector equation g=0
  p = SNLE(g,x0,lb=lb,ub=ub,Aeq = Aeq,beq=beq, A =A,b=b)
  r = p.solve('nssolve')



  #this presents the output
  if r.stopcase==1:
      formatted = ()
      for m in r.xf:
          formatted = formatted + (round(m,2),)
      print 'The agent prefers L over Lp. The solver result is', formatted
  elif r.stopcase==0:
      print 'The solver cannot solve the problem. The implication might or might not be valid.'
  else:
      print 'No implication can be made from the given preference relations.'

#+end_src

#+RESULTS:
#+begin_example

>>> >>> >>> >>> >>> >>> >>> >>> >>> >>> >>> >>> >>> >>> >>> >>> >>> >>> >>> >>> ... ... ... ... ... ... ... ... >>> >>> ... ... ... ... ... ... ... >>> ... >>> >>> >>> ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... >>> ... >>> 
------------------------- OpenOpt 0.5621 -------------------------
problem: unnamed   type: SNLE
solver: nssolve
  iter  objFunVal  log10(maxResidual)  
    0  2.500e-01              -0.30 
   10  6.724e-02             -15.65 
   20  1.954e-03              -3.58 
   30  1.468e-04              -2.96 
   40  3.694e-05             -15.11 
   50  4.784e-06             -15.00 
   60  5.783e-07              -6.28 
istop: 15 (solution with required ftol and contol has been reached)
Solver:   Time Elapsed = 0.24 	CPU Time Elapsed = 0.24
objFunValue: 5.7830664e-07 (feasible, MaxResidual = 5.2312e-07)
... ... ... ... ... ... ... ... ... ... The agent prefers L over Lp. The solver result is (0.25, 0.5, -0.0, 0.0, 1.0)
#+end_example

** An exercise generator

Finally, want to have a little exercise generator. It will generate two preference relations. Given the first preference relation, the second is implied by the independence axiom and you can try to figure out why. You can use the program above to check your solution.

#+begin_src python  :results output :exports both :tangle lottery_exercise_generator.py
  import numpy
  import random

  L1 = []
  L1p = []
  L_mult=[]


  prob1 = 100#will make sure that probabilities in lottery L1 sum to 1
  prob1p = 100#will make sure that probabilities in lottery L1p sum to 1
  prob_mult = 100 #will make sure that probabilities in the lottery that has to be found sum to 1

  for j in range(2):
      rand1 = random.randint(0,prob1-2+j)
      L1.append(rand1/100.0)
      prob1 = prob1 - rand1
      rand1p = random.randint(0,prob1p-2+j)
      L1p.append(rand1p/100.0)
      prob1p = prob1p - rand1p
      rand_mult = random.randint(0,prob_mult-2+j)
      L_mult.append(rand_mult/100.0)
      prob_mult= prob_mult - rand_mult
      
      
  L1.append(prob1/100.0)
  L1p.append(prob1p/100.0)
  L_mult.append(prob_mult/100.0)

  weight = (random.randint(1,9))/10.0


  L = numpy.asarray(L1)*weight + numpy.asarray(L_mult)*(1-weight)
  Lp = numpy.asarray(L1p)*weight + numpy.asarray(L_mult)*(1-weight)

  print 'The agent prefers lottery L1=',L1,' to lottery L1p=',L1p,'. Does this imply that he prefers lottery L=',L,' to lottery Lp=',Lp,'?'
#+end_src

#+RESULTS:
: The agent prefers lottery L1= [0.76, 0.04, 0.2]  to lottery L1p= [0.79, 0.05, 0.16] . Does this imply that he prefers lotters L= [ 0.691  0.112  0.197]  to lottery Lp= [ 0.718  0.121  0.161] ?

